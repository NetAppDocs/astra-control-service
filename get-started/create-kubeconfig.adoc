---
sidebar: sidebar
permalink: get-started/create-kubeconfig.html
keywords: kubeconfig, create, config file, file, config
summary: You need to create an admin-role kubeconfig file for self-managed clusters.
---

= Create a kubeconfig file
:hardbreaks:
:icons: font
:imagesdir: ../media/get-started/

[.lead]
You can add a cluster to Astra Control Service using a kubeconfig file. Depending on the type of cluster you want to add, you might need to manually create a kubeconfig file for your cluster using specific steps.

* <<Create a kubeconfig file for Amazon EKS clusters>>
* <<Create a kubeconfig file for Red Hat OpenShift Service on AWS (ROSA) clusters>>
* <<Create a kubeconfig file for other types of clusters>>

== Create a kubeconfig file for Amazon EKS clusters

Follow these instructions to create a kubeconfig file and permanent token secret for Amazon EKS clusters. A permanent token secret is required for clusters hosted in EKS.

.Steps

. Follow the instructions in the Amazon documentation to generate a kubeconfig file:
+
https://docs.aws.amazon.com/eks/latest/userguide/create-kubeconfig.html[Creating or updating a kubeconfig file for an Amazon EKS cluster^]

. Create a service account as follows:
.. Create a service account file called `astracontrol-service-account.yaml`.
+
Adjust the service account name as needed. The namespace `kube-system` is required for these steps. If you change the service account name here, you should apply the same changes in the following steps.
+
[source]
[subs="specialcharacters,quotes"]
----
*astracontrol-service-account.yaml*
----
+
[source,yaml]
----
apiVersion: v1
kind: ServiceAccount
metadata:
  name: astra-admin-account
  namespace: kube-system
----

. Apply the service account:
+
[source,console]
----
kubectl apply -f astracontrol-service-account.yaml
----

. Create a `ClusterRoleBinding` file called `astracontrol-clusterrolebinding.yaml`.
+
[source]
[subs="specialcharacters,quotes"]
----
*astracontrol-clusterrolebinding.yaml*
----
+
[source,yaml]
----
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: astra-admin-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: astra-admin-account
  namespace: kube-system
----

. Apply the cluster role binding:
+
[source,console]
----
kubectl apply -f astracontrol-clusterrolebinding.yaml
----

. Create a service account token secret file called `astracontrol-secret.yaml`.
+
[source]
[subs="specialcharacters,quotes"]
----
*astracontrol-secret.yaml*
----
+
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  annotations:
    kubernetes.io/service-account.name: astra-admin-account
  name: astra-admin-account
  namespace: kube-system
type: kubernetes.io/service-account-token
----

. Apply the token secret:
+
[source,console]
----
kubectl apply -f astracontrol-secret.yaml
----

. Retrieve the token secret:
+
[source,console]
----
kubectl get secret astra-admin-account -n kube-system -o jsonpath='{.data.token}' | base64 -d
----

. Replace the `user` section of the AWS EKS kubeconfig file with the token, as shown in the following example:
+
[source,yaml]
----
user:
    token: k8s-aws-v1.aHR0cHM6Ly9zdHMudXMtd2VzdC0yLmFtYXpvbmF3cy5jb20vP0FjdGlvbj1HZXRDYWxsZXJJZGVudGl0eSZWZXJzaW9uPTIwMTEtMDYtMTUmWC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBM1JEWDdKU0haWU9LSEQ2SyUyRjIwMjMwNDAzJTJGdXMtd2VzdC0yJTJGc3RzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMzA0MDNUMjA0MzQwWiZYLUFtei1FeHBpcmVzPTYwJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCUzQngtazhzLWF3cy1pZCZYLUFtei1TaWduYXR1cmU9YjU4ZWM0NzdiM2NkZGYxNGRhNzU4MGI2ZWQ2zY2NzI2YWIwM2UyNThjMjRhNTJjNmVhNjc4MTRlNjJkOTg2Mg
----

== Create a kubeconfig file for Red Hat OpenShift Service on AWS (ROSA) clusters
Follow these instructions to create a kubeconfig file for Red Hat OpenShift Service on AWS (ROSA) clusters.

.Steps

. Log in to the ROSA cluster.
. Create a service account:
+
[source,console]
----
oc create sa astracontrol-service-account
----
. Add a cluster role:
+
[source,console]
----
oc adm policy add-cluster-role-to-user cluster-admin -z astracontrol-service-account
----
. Using the following example, create a service account secret configuration file:
+
[source]
[subs="specialcharacters,quotes"]
----
*secret-astra-sa.yaml*
----
+
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  name: secret-astracontrol-service-account
  annotations:
    kubernetes.io/service-account.name: "astracontrol-service-account" 
type: kubernetes.io/service-account-token
----
. Create the secret:
+
[source,console]
----
oc create -f secret-astra-sa.yaml
----
. Edit the service account that you created, and add the Astra Control service account secret name to the `secrets` section:
+
[source,console]
----
oc edit sa astracontrol-service-account
----
+
[source,yaml]
----
apiVersion: v1
imagePullSecrets:
- name: astracontrol-service-account-dockercfg-dvfcd
kind: ServiceAccount
metadata:
  creationTimestamp: "2023-08-04T04:18:30Z"
  name: astracontrol-service-account
  namespace: default
  resourceVersion: "169770"
  uid: 965fa151-923f-4fbd-9289-30cad15998ac
secrets:
- name: astracontrol-service-account-dockercfg-dvfcd
- name: secret-astracontrol-service-account ####ADD THIS ONLY####
----
. List the service account secrets, replacing `<CONTEXT>` with the correct context for your installation:
+
[source,console]
----
kubectl get serviceaccount astracontrol-service-account --context <CONTEXT> --namespace default -o json
----
+
The end of the output should look similar to the following:
+
----
"secrets": [
{ "name": "astracontrol-service-account-dockercfg-dvfcd"},
{ "name": "secret-astracontrol-service-account"}
]
----
+
The indices for each element in the `secrets` array begin with 0. In the above example, the index for `astracontrol-service-account-dockercfg-dvfcd` would be 0 and the index for `secret-astracontrol-service-account` would be 1. In your output, make note of the index number for the service account secret. You will need this index number in the next step.

. Generate the kubeconfig as follows:
.. Create a `create-kubeconfig.sh` file. Replace `TOKEN_INDEX` in the beginning of the following script with the correct value.
+
[source]
[subs="specialcharacters,quotes"]
----
*create-kubeconfig.sh*
----
+
[source,bash]
----
# Update these to match your environment.
# Replace TOKEN_INDEX with the correct value
# from the output in the previous step. If you
# didn't change anything else above, don't change
# anything else here.

SERVICE_ACCOUNT_NAME=astracontrol-service-account
NAMESPACE=default
NEW_CONTEXT=astracontrol
KUBECONFIG_FILE='kubeconfig-sa'

CONTEXT=$(kubectl config current-context)

SECRET_NAME=$(kubectl get serviceaccount ${SERVICE_ACCOUNT_NAME} \
  --context ${CONTEXT} \
  --namespace ${NAMESPACE} \
  -o jsonpath='{.secrets[TOKEN_INDEX].name}')
TOKEN_DATA=$(kubectl get secret ${SECRET_NAME} \
  --context ${CONTEXT} \
  --namespace ${NAMESPACE} \
  -o jsonpath='{.data.token}')

TOKEN=$(echo ${TOKEN_DATA} | base64 -d)

# Create dedicated kubeconfig
# Create a full copy
kubectl config view --raw > ${KUBECONFIG_FILE}.full.tmp

# Switch working context to correct context
kubectl --kubeconfig ${KUBECONFIG_FILE}.full.tmp config use-context ${CONTEXT}

# Minify
kubectl --kubeconfig ${KUBECONFIG_FILE}.full.tmp \
  config view --flatten --minify > ${KUBECONFIG_FILE}.tmp

# Rename context
kubectl config --kubeconfig ${KUBECONFIG_FILE}.tmp \
  rename-context ${CONTEXT} ${NEW_CONTEXT}

# Create token user
kubectl config --kubeconfig ${KUBECONFIG_FILE}.tmp \
  set-credentials ${CONTEXT}-${NAMESPACE}-token-user \
  --token ${TOKEN}

# Set context to use token user
kubectl config --kubeconfig ${KUBECONFIG_FILE}.tmp \
  set-context ${NEW_CONTEXT} --user ${CONTEXT}-${NAMESPACE}-token-user

# Set context to correct namespace
kubectl config --kubeconfig ${KUBECONFIG_FILE}.tmp \
  set-context ${NEW_CONTEXT} --namespace ${NAMESPACE}

# Flatten/minify kubeconfig
kubectl config --kubeconfig ${KUBECONFIG_FILE}.tmp \
  view --flatten --minify > ${KUBECONFIG_FILE}

# Remove tmp
rm ${KUBECONFIG_FILE}.full.tmp
rm ${KUBECONFIG_FILE}.tmp
----
.. Source the commands to apply them to your Kubernetes cluster.
+
[source,console]
----
source create-kubeconfig.sh
----
. (Optional) Rename the kubeconfig to a meaningful name for your cluster.
+
----
mv kubeconfig-sa YOUR_CLUSTER_NAME_kubeconfig
----


== Create a kubeconfig file for other types of clusters


Follow these instructions to create a limited or expanded role kubeconfig file for Rancher, Upstream Kubernetes, and Red Hat OpenShift clusters.

For clusters that are managed using kubeconfig, you can optionally create a limited permission or expanded permission administrator role for Astra Control Service.

This procedure helps you to create a separate kubeconfig if either of the following scenarios applies to your environment:

* You want to limit Astra Control permissions on the clusters it manages
* You use multiple contexts and cannot use the default Astra Control kubeconfig configured during installation or a limited role with a single context won't work in your environment

.Before you begin

Ensure that you have the following for the cluster you intend to manage before completing the procedure steps:

* A link:../get-started/add-private-self-managed-cluster.html#supported-kubernetes-distributions[supported version] of kubectl is installed.
* kubectl access to the cluster that you intend to add and manage with Astra Control Service
+
NOTE: For this procedure, you do not need kubectl access to the cluster that is running Astra Control Service.

* An active kubeconfig for the cluster you intend to manage with cluster admin rights for the active context

.Steps
. Create a service account:
.. Create a service account file called `astracontrol-service-account.yaml`.
//+
//Adjust the name and namespace as needed. If changes are made here, you should apply the same changes in the following steps.
+
[source]
[subs="specialcharacters,quotes"]
----
*astracontrol-service-account.yaml*
----
+
[source,yaml]
----
apiVersion: v1
kind: ServiceAccount
metadata:
  name: astracontrol-service-account
  namespace: default
----
.. Apply the service account:
+
[source,console]
----
kubectl apply -f astracontrol-service-account.yaml
----

. Create one of the following cluster roles with sufficient permissions for a cluster to be managed by Astra Control:
+
[role="tabbed-block"]
====

.Limited cluster role
--
This role contains the minimum permissions necessary for a cluster to be managed by Astra Control:

. Create a `ClusterRole` file called, for example, `astra-admin-account.yaml`.
//+
//Adjust the name and namespace as needed. If changes are made here, you should apply the same changes in the following steps.
+
[source]
[subs="specialcharacters,quotes"]
----
*astra-admin-account.yaml*
----
+
[source,yaml]
----
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: astra-admin-account
rules:
 
# Get, List, Create, and Update all resources
# Necessary to backup and restore all resources in an app
- apiGroups:
  - '*'
  resources:
  - '*'
  verbs:
  - get
  - list
  - create
  - patch
 
# Delete Resources
# Necessary for in-place restore and AppMirror failover
- apiGroups:
  - ""
  - apps
  - autoscaling
  - batch
  - crd.projectcalico.org
  - extensions
  - networking.k8s.io
  - policy
  - rbac.authorization.k8s.io
  - snapshot.storage.k8s.io
  - trident.netapp.io
  resources:
  - configmaps
  - cronjobs
  - daemonsets
  - deployments
  - horizontalpodautoscalers
  - ingresses
  - jobs
  - namespaces
  - networkpolicies
  - persistentvolumeclaims
  - poddisruptionbudgets
  - pods
  - podtemplates
  - replicasets
  - replicationcontrollers
  - replicationcontrollers/scale
  - rolebindings
  - roles
  - secrets
  - serviceaccounts
  - services
  - statefulsets
  - tridentmirrorrelationships
  - tridentsnapshotinfos
  - volumesnapshots
  - volumesnapshotcontents
  verbs:
  - delete
 
# Watch resources
# Necessary to monitor progress
- apiGroups:
  - ""
  resources:
  - pods
  - replicationcontrollers
  - replicationcontrollers/scale
  verbs:
  - watch
 
# Update resources
- apiGroups:
  - ""
  - build.openshift.io
  - image.openshift.io
  resources:
  - builds/details
  - replicationcontrollers
  - replicationcontrollers/scale
  - imagestreams/layers
  - imagestreamtags
  - imagetags
  verbs:
  - update
----

. (For OpenShift clusters only) Append the following at the end of the `astra-admin-account.yaml` file:
+
[source,console]
----
# OpenShift security
- apiGroups:
  - security.openshift.io
  resources:
  - securitycontextconstraints
  verbs:
  - use
  - update
----

. Apply the cluster role:
+
[source,console]
----
kubectl apply -f astra-admin-account.yaml
----

--

.Expanded cluster role
--
This role contains expanded permissions for a cluster to be managed by Astra Control. You might use this role if you use multiple contexts and cannot use the default Astra Control kubeconfig configured during installation or a limited role with a single context won't work in your environment:

NOTE: The following `ClusterRole` steps are a general Kubernetes example. Refer to the documentation for your Kubernetes distribution for instructions specific to your environment.

. Create a `ClusterRole` file called, for example, `astra-admin-account.yaml`.
//+
//Adjust the name and namespace as needed. If changes are made here, you should apply the same changes in the following steps.
+
[source]
[subs="specialcharacters,quotes"]
----
*astra-admin-account.yaml*
----
+
[source,yaml]
----
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: astra-admin-account
rules:
- apiGroups:
  - '*'
  resources:
  - '*'
  verbs:
  - '*'
- nonResourceURLs:
  - '*'
  verbs:
  - '*'
----

. Apply the cluster role:
+
[source,console]
----
kubectl apply -f astra-admin-account.yaml
----

--

====

. Create the cluster role binding for the cluster role to the service account:
.. Create a `ClusterRoleBinding` file called `astracontrol-clusterrolebinding.yaml`.
//+
//Adjust any names and namespaces modified when creating the service account as needed.
+
[source]
[subs="specialcharacters,quotes"]
----
*astracontrol-clusterrolebinding.yaml*
----
+
[source,yaml]
----
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: astracontrol-admin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: astra-admin-account
subjects:
- kind: ServiceAccount
  name: astracontrol-service-account
  namespace: default
----
+
.. Apply the cluster role binding:
+
[source,console]
----
kubectl apply -f astracontrol-clusterrolebinding.yaml
----
. Create and apply the token secret:
.. Create a token secret file called `secret-astracontrol-service-account.yaml`.
+
[source]
[subs="specialcharacters,quotes"]
----
*secret-astracontrol-service-account.yaml*
----
+
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  name: secret-astracontrol-service-account
  namespace: default
  annotations:
    kubernetes.io/service-account.name: "astracontrol-service-account"
type: kubernetes.io/service-account-token
----
.. Apply the token secret:
+
[source,console]
----
kubectl apply -f secret-astracontrol-service-account.yaml
----

. Add the token secret to the service account by adding its name to the `secrets` array (the last line in the following example):
+
[source,console]
----
kubectl edit sa astracontrol-service-account
----
+
[source,subs="verbatim,quotes"]
----
apiVersion: v1
imagePullSecrets:
- name: astracontrol-service-account-dockercfg-48xhx
kind: ServiceAccount
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"name":"astracontrol-service-account","namespace":"default"}}
  creationTimestamp: "2023-06-14T15:25:45Z"
  name: astracontrol-service-account
  namespace: default
  resourceVersion: "2767069"
  uid: 2ce068c4-810e-4a96-ada3-49cbf9ec3f89
secrets:
- name: astracontrol-service-account-dockercfg-48xhx
*- name: secret-astracontrol-service-account*
----

. List the service account secrets, replacing `<context>` with the correct context for your installation:
+
[source,console]
----
kubectl get serviceaccount astracontrol-service-account --context <context> --namespace default -o json
----
+
The end of the output should look similar to the following:
+
----
"secrets": [
{ "name": "astracontrol-service-account-dockercfg-48xhx"},
{ "name": "secret-astracontrol-service-account"}
]
----
+
The indices for each element in the `secrets` array begin with 0. In the above example, the index for `astracontrol-service-account-dockercfg-48xhx` would be 0 and the index for `secret-astracontrol-service-account` would be 1. In your output, make note of the index number for the service account secret. You'll need this index number in the next step.
. Generate the kubeconfig as follows:
.. Create a `create-kubeconfig.sh` file. 
.. Replace `TOKEN_INDEX` in the beginning of the following script with the correct value.
+
[source]
[subs="specialcharacters,quotes"]
----
*create-kubeconfig.sh*
----
+
[source,subs="verbatim,quotes"]
----
# Update these to match your environment.
# Replace TOKEN_INDEX with the correct value
# from the output in the previous step. If you
# didn't change anything else above, don't change
# anything else here.

SERVICE_ACCOUNT_NAME=astracontrol-service-account
NAMESPACE=default
NEW_CONTEXT=astracontrol
KUBECONFIG_FILE='kubeconfig-sa'

CONTEXT=$(kubectl config current-context)

SECRET_NAME=$(kubectl get serviceaccount ${SERVICE_ACCOUNT_NAME} \
  --context ${CONTEXT} \
  --namespace ${NAMESPACE} \
  *-o jsonpath='{.secrets[TOKEN_INDEX].name}')
TOKEN_DATA=$(kubectl get secret ${SECRET_NAME} \
  --context ${CONTEXT} \
  --namespace ${NAMESPACE} \
  -o jsonpath='{.data.token}')

TOKEN=$(echo ${TOKEN_DATA} | base64 -d)

# Create dedicated kubeconfig
# Create a full copy
kubectl config view --raw > ${KUBECONFIG_FILE}.full.tmp

# Switch working context to correct context
kubectl --kubeconfig ${KUBECONFIG_FILE}.full.tmp config use-context ${CONTEXT}

# Minify
kubectl --kubeconfig ${KUBECONFIG_FILE}.full.tmp \
  config view --flatten --minify > ${KUBECONFIG_FILE}.tmp

# Rename context
kubectl config --kubeconfig ${KUBECONFIG_FILE}.tmp \
  rename-context ${CONTEXT} ${NEW_CONTEXT}

# Create token user
kubectl config --kubeconfig ${KUBECONFIG_FILE}.tmp \
  set-credentials ${CONTEXT}-${NAMESPACE}-token-user \
  --token ${TOKEN}

# Set context to use token user
kubectl config --kubeconfig ${KUBECONFIG_FILE}.tmp \
  set-context ${NEW_CONTEXT} --user ${CONTEXT}-${NAMESPACE}-token-user

# Set context to correct namespace
kubectl config --kubeconfig ${KUBECONFIG_FILE}.tmp \
  set-context ${NEW_CONTEXT} --namespace ${NAMESPACE}

# Flatten/minify kubeconfig
kubectl config --kubeconfig ${KUBECONFIG_FILE}.tmp \
  view --flatten --minify > ${KUBECONFIG_FILE}

# Remove tmp
rm ${KUBECONFIG_FILE}.full.tmp
rm ${KUBECONFIG_FILE}.tmp
----
.. Source the commands to apply them to your Kubernetes cluster.
+
[source,console]
----
source create-kubeconfig.sh
----
. (Optional) Rename the kubeconfig to a meaningful name for your cluster.
+
----
mv kubeconfig-sa YOUR_CLUSTER_NAME_kubeconfig
----