---
sidebar: sidebar
permalink: get-started/create-kubeconfig.html
keywords: kubeconfig, create, config file, file, config
summary: You need to create an admin-role kubeconfig file for self-managed clusters.
---

= Create a kubeconfig file
:hardbreaks:
:icons: font
:imagesdir: ../media/get-started/

[.lead]
You can add a cluster to Astra Control Service using a kubeconfig file. Depending on the type of cluster you want to add, you might need to manually create a kubeconfig file for your cluster using specific steps.

* <<Create a kubeconfig file for Amazon EKS clusters>>
* <<Create a kubeconfig file for other types of clusters>>

== Create a kubeconfig file for Amazon EKS clusters

Follow these instructions to create a kubeconfig file and permanent token secret for Amazon EKS clusters. A permanent token secret is required for clusters hosted in EKS.

.Steps

. Follow the instructions in the Amazon documentation to generate a kubeconfig file:
+
https://docs.aws.amazon.com/eks/latest/userguide/create-kubeconfig.html[Creating or updating a kubeconfig file for an Amazon EKS cluster^]

. Create a service account as follows:
.. Create a service account file called `astracontrol-service-account.yaml`.
+
Adjust the service account name as needed. The namespace `kube-system` is required for these steps. If you change the service account name here, you should apply the same changes in the following steps.
+
[source]
[subs="specialcharacters,quotes"]
----
*astracontrol-service-account.yaml*
----
+
[source,yaml]
----
apiVersion: v1
kind: ServiceAccount
metadata:
  name: astra-admin-account
  namespace: kube-system
----

. Apply the service account:
+
[source,console]
----
kubectl apply -f astracontrol-service-account.yaml
----

. Create a `ClusterRoleBinding` file called `astracontrol-clusterrolebinding.yaml`.
+
[source]
[subs="specialcharacters,quotes"]
----
*astracontrol-clusterrolebinding.yaml*
----
+
[source,yaml]
----
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: astra-admin-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: astra-admin-account
  namespace: kube-system
----

. Apply the cluster role binding:
+
[source,console]
----
kubectl apply -f astracontrol-clusterrolebinding.yaml
----

. Create a service account token secret file called `astracontrol-secret.yaml`.
+
[source]
[subs="specialcharacters,quotes"]
----
*astracontrol-secret.yaml*
----
+
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  annotations:
    kubernetes.io/service-account.name: astra-admin-account
  name: astra-admin-account
  namespace: kube-system
type: kubernetes.io/service-account-token
----

. Apply the token secret:
+
[source,console]
----
kubectl apply -f astracontrol-secret.yaml
----

. Retrieve the token secret:
+
[source,console]
----
kubectl get secret astra-admin-account -n kube-system -o jsonpath='{.data.token}' | base64 -d
----

. Replace the `user` section of the AWS EKS kubeconfig file with the token, as shown in the following example:
+
[source,yaml]
----
user:
    token: k8s-aws-v1.aHR0cHM6Ly9zdHMudXMtd2VzdC0yLmFtYXpvbmF3cy5jb20vP0FjdGlvbj1HZXRDYWxsZXJJZGVudGl0eSZWZXJzaW9uPTIwMTEtMDYtMTUmWC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBM1JEWDdKU0haWU9LSEQ2SyUyRjIwMjMwNDAzJTJGdXMtd2VzdC0yJTJGc3RzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMzA0MDNUMjA0MzQwWiZYLUFtei1FeHBpcmVzPTYwJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCUzQngtazhzLWF3cy1pZCZYLUFtei1TaWduYXR1cmU9YjU4ZWM0NzdiM2NkZGYxNGRhNzU4MGI2ZWQ2zY2NzI2YWIwM2UyNThjMjRhNTJjNmVhNjc4MTRlNjJkOTg2Mg
----

== Create a kubeconfig file for other types of clusters

Follow these instructions to create a kubeconfig file for Rancher, Upstream Kubernetes, and Red Hat OpenShift clusters.

.Before you begin

Ensure that you have the following on your machine before you start:

* kubectl v1.25 or later installed
* kubectl access to the cluster that you intend to add and manage with Astra Control Center
+
NOTE: For this procedure, you do not need kubectl access to the cluster that is running Astra Control Center.

* An active kubeconfig for the cluster you intend to manage with cluster admin rights for the active context

.Steps
. Create a service account:
.. Create a service account file called `astracontrol-service-account.yaml`.
+
Adjust the name and namespace as needed. If changes are made here, you should apply the same changes in the following steps.
+
[source]
[subs="specialcharacters,quotes"]
----
*astracontrol-service-account.yaml*
----
+
[source,yaml]
----
apiVersion: v1
kind: ServiceAccount
metadata:
  name: astracontrol-service-account
  namespace: default
----
.. Apply the service account:
+
[source,console]
----
kubectl apply -f astracontrol-service-account.yaml
----

. Create one of the following cluster roles with sufficient permissions for a cluster to be managed by Astra Control:
* *Limited cluster role*: This role contains the minimum permissions necessary for a cluster to be managed by Astra Control:
+
.Expand for steps
[%collapsible]
====
.. Create a `ClusterRole` file called, for example, `astra-admin-account.yaml`.
+
Adjust the name and namespace as needed. If changes are made here, you should apply the same changes in the following steps.
+
[source]
[subs="specialcharacters,quotes"]
----
*astra-admin-account.yaml*
----
+
[source,yaml]
----
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: astra-admin-account
rules:

# Justification for resource permissions:

# Astra Control needs to be able to discover (list) resources of all types within your application.
# These permissions are required to discover, back up, and restore your application resources including
# secrets.
# For example, if your application contains custom resources or cluster-scoped resources, Astra Control
# needs '*' to discover, back up, and restore your application resources.
 
# Justification for Verbs:
# - "List" enables discovery.
# - "Get" enables resource backups and enables users to define apps using GVK.
# - "Create" enables restoring an application from a snapshot or backup using Astra Control.
# - "Delete" enables application resource clean-up as part of an in-place restore of an application or clones.
# - "Patch" enables maintaining owner references and updating labels on some resources.
# - "Update" enables replica scaling in case of operations like in-place restores of your application.
# - "Watch" enables Astra Control to keep an up to date view of resources. 

# Manage all resources
# Necessary to back up and restore all resources in an app
- apiGroups:
  - '*'
  resources:
  - '*'
  verbs:
  - get
  - list
  - create
  - patch
  - delete
  - watch
  - update

- nonResourceURLs:
  - /metrics
  verbs:
  - get
  - watch
  - list
 
# Delete Resources
# Necessary for in-place restore
- apiGroups:
  - ""
  - apps
  - autoscaling
  - batch
  - crd.projectcalico.org
  - extensions
  - networking.k8s.io
  - policy
  - rbac.authorization.k8s.io
  - snapshot.storage.k8s.io
  - trident.netapp.io
  resources:
  - configmaps
  - cronjobs
  - daemonsets
  - deployments
  - horizontalpodautoscalers
  - ingresses
  - jobs
  - namespaces
  - networkpolicies
  - persistentvolumeclaims
  - poddisruptionbudgets
  - pods
  - podtemplates
  - podsecuritypolicies
  - replicasets
  - replicationcontrollers
  - replicationcontrollers/scale
  - rolebindings
  - roles
  - secrets
  - serviceaccounts
  - services
  - statefulsets
  - tridentmirrorrelationships
  - tridentsnapshotinfos
  - volumesnapshots
  - volumesnapshotcontents
  verbs:
  - delete
 
# Watch resources
# Necessary to monitor progress
- apiGroups:
  - ""
  resources:
  - pods
  - replicationcontrollers
  - replicationcontrollers/scale
  verbs:
  - watch
 
# Update resources
- apiGroups:
  - ""
  - build.openshift.io
  - image.openshift.io
  resources:
  - builds/details
  - replicationcontrollers
  - replicationcontrollers/scale
  - imagestreams/layers
  - imagestreamtags
  - imagetags
  verbs:
  - update
 
# Use PodSecurityPolicies
- apiGroups:
  - extensions
  - policy
  resources:
  - podsecuritypolicies
  verbs:
  - use

# OpenShift security - uncomment these lines for Red Hat OpenShift clusters
#- apiGroups:
#  - security.openshift.io
#  resources:
#  - securitycontextconstraints
#  verbs:
#  - use
----

.. (For OpenShift clusters only) Append the following at the end of the `astra-admin-account.yaml` file or after the `# Use PodSecurityPolicies` section:
+
[source,console]
----
# OpenShift security
- apiGroups:
  - security.openshift.io
  resources:
  - securitycontextconstraints
  verbs:
  - use
----

.. Apply the cluster role:
+
[source,console]
----
kubectl apply -f astra-admin-account.yaml
----

====
// End snippet

* *Expanded cluster role*: This role contains expanded permissions for a cluster to be managed by Astra Control. You might use this role if you use multiple contexts and cannot use the default Astra Control kubeconfig configured during installation or a limited role with a single context won't work in your environment:
+
NOTE: The following `ClusterRole` steps are a general Kubernetes example. Refer to the documentation for your Kubernetes distribution for instructions specific to your environment.
+
.Expand for steps
[%collapsible]
====
.. Create a `ClusterRole` file called, for example, `astra-admin-account.yaml`.
+
Adjust the name and namespace as needed. If changes are made here, you should apply the same changes in the following steps.
+
[source]
[subs="specialcharacters,quotes"]
----
*astra-admin-account.yaml*
----
+
[source,yaml]
----
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: astra-admin-account
rules:
- apiGroups:
  - '*'
  resources:
  - '*'
  verbs:
  - '*'
- nonResourceURLs:
  - '*'
  verbs:
  - '*'
----

.. Apply the cluster role:
+
[source,console]
----
kubectl apply -f astra-admin-account.yaml
----
====
// End snippet

. Create the cluster role binding for the cluster role to the service account:
.. Create a `ClusterRoleBinding` file called `astracontrol-clusterrolebinding.yaml`.
+
Adjust any names and namespaces modified when creating the service account as needed.
+
[source]
[subs="specialcharacters,quotes"]
----
*astracontrol-clusterrolebinding.yaml*
----
+
[source,yaml]
----
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: astracontrol-admin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: astra-admin-account
subjects:
- kind: ServiceAccount
  name: astracontrol-service-account
  namespace: default
----
+
.. Apply the cluster role binding:
+
[source,console]
----
kubectl apply -f astracontrol-clusterrolebinding.yaml
----
. Create and apply the token secret:
.. Create a token secret file called `secret-astracontrol-service-account.yaml`.
+
[source]
[subs="specialcharacters,quotes"]
----
*secret-astracontrol-service-account.yaml*
----
+
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  name: secret-astracontrol-service-account
  namespace: default
  annotations:
    kubernetes.io/service-account.name: "astracontrol-service-account"
type: kubernetes.io/service-account-token
----
.. Apply the token secret:
+
[source,console]
----
kubectl apply -f secret-astracontrol-service-account.yaml
----

. Add the token secret to the service account by adding its name to the `secrets` array (the last line in the following example):
+
[source,console]
----
kubectl edit sa astracontrol-service-account
----
+
[source,subs="verbatim,quotes"]
----
apiVersion: v1
imagePullSecrets:
- name: astracontrol-service-account-dockercfg-48xhx
kind: ServiceAccount
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"name":"astracontrol-service-account","namespace":"default"}}
  creationTimestamp: "2023-06-14T15:25:45Z"
  name: astracontrol-service-account
  namespace: default
  resourceVersion: "2767069"
  uid: 2ce068c4-810e-4a96-ada3-49cbf9ec3f89
secrets:
- name: astracontrol-service-account-dockercfg-48xhx
*- name: secret-astracontrol-service-account*
----

. List the service account secrets, replacing `<context>` with the correct context for your installation:
+
[source,console]
----
kubectl get serviceaccount astracontrol-service-account --context <context> --namespace default -o json
----
+
The end of the output should look similar to the following:
+
----
"secrets": [
{ "name": "astracontrol-service-account-dockercfg-48xhx"},
{ "name": "secret-astracontrol-service-account"}
]
----
+
The indices for each element in the `secrets` array begin with 0. In the above example, the index for `astracontrol-service-account-dockercfg-48xhx` would be 0 and the index for `secret-astracontrol-service-account` would be 1. In your output, make note of the index number for the service account secret. You will need this index number in the next step.
. Generate the kubeconfig as follows:
.. Create a `create-kubeconfig.sh` file. Replace `TOKEN_INDEX` in the beginning of the following script with the correct value.
+
[source]
[subs="specialcharacters,quotes"]
----
*create-kubeconfig.sh*
----
+
[source,console]
----
# Update these to match your environment.
# Replace TOKEN_INDEX with the correct value
# from the output in the previous step. If you
# didn't change anything else above, don't change
# anything else here.

SERVICE_ACCOUNT_NAME=astracontrol-service-account
NAMESPACE=default
NEW_CONTEXT=astracontrol
KUBECONFIG_FILE='kubeconfig-sa'

CONTEXT=$(kubectl config current-context)

SECRET_NAME=$(kubectl get serviceaccount ${SERVICE_ACCOUNT_NAME} \
  --context ${CONTEXT} \
  --namespace ${NAMESPACE} \
  -o jsonpath='{.secrets[TOKEN_INDEX].name}')
TOKEN_DATA=$(kubectl get secret ${SECRET_NAME} \
  --context ${CONTEXT} \
  --namespace ${NAMESPACE} \
  -o jsonpath='{.data.token}')

TOKEN=$(echo ${TOKEN_DATA} | base64 -d)

# Create dedicated kubeconfig
# Create a full copy
kubectl config view --raw > ${KUBECONFIG_FILE}.full.tmp

# Switch working context to correct context
kubectl --kubeconfig ${KUBECONFIG_FILE}.full.tmp config use-context ${CONTEXT}

# Minify
kubectl --kubeconfig ${KUBECONFIG_FILE}.full.tmp \
  config view --flatten --minify > ${KUBECONFIG_FILE}.tmp

# Rename context
kubectl config --kubeconfig ${KUBECONFIG_FILE}.tmp \
  rename-context ${CONTEXT} ${NEW_CONTEXT}

# Create token user
kubectl config --kubeconfig ${KUBECONFIG_FILE}.tmp \
  set-credentials ${CONTEXT}-${NAMESPACE}-token-user \
  --token ${TOKEN}

# Set context to use token user
kubectl config --kubeconfig ${KUBECONFIG_FILE}.tmp \
  set-context ${NEW_CONTEXT} --user ${CONTEXT}-${NAMESPACE}-token-user

# Set context to correct namespace
kubectl config --kubeconfig ${KUBECONFIG_FILE}.tmp \
  set-context ${NEW_CONTEXT} --namespace ${NAMESPACE}

# Flatten/minify kubeconfig
kubectl config --kubeconfig ${KUBECONFIG_FILE}.tmp \
  view --flatten --minify > ${KUBECONFIG_FILE}

# Remove tmp
rm ${KUBECONFIG_FILE}.full.tmp
rm ${KUBECONFIG_FILE}.tmp
----
.. Source the commands to apply them to your Kubernetes cluster.
+
[source,console]
----
source create-kubeconfig.sh
----
. (Optional) Rename the kubeconfig to a meaningful name for your cluster.
+
----
mv kubeconfig-sa YOUR_CLUSTER_NAME_kubeconfig
----
